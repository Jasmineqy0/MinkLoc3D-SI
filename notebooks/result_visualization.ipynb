{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "tf_logdir = '../tf_logs/'\n",
    "weights_dir = '../weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finished_configs(tf_logdir):\n",
    "    \"\"\"\n",
    "    Get the list of finished configs, return a list.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tf_logdir):\n",
    "        raise ValueError('The directory {} does not exist.'.format(tf_logdir))\n",
    "\n",
    "    configs, dirs = [], []\n",
    "    for dir in os.listdir(tf_logdir):\n",
    "        if os.path.exists(os.path.join(tf_logdir, dir, 'config.json')):\n",
    "            dirs.append(dir)\n",
    "            with open(os.path.join(tf_logdir, dir, 'config.json')) as f:\n",
    "                config = json.load(f)\n",
    "                configs.append(config)\n",
    "    return configs, dirs\n",
    "\n",
    "def get_columns(configs, dirs): \n",
    "\n",
    "    # data-related columns\n",
    "    datasets = []\n",
    "    epochs = []\n",
    "    batch_size = []\n",
    "    batch_size_limit = []\n",
    "\n",
    "    # model-related columns\n",
    "    version = []\n",
    "    backbone = []\n",
    "    pooling = []\n",
    "    pointnet = []\n",
    "    pointnet_pnt2s = []\n",
    "    self_attention = []\n",
    "    self_attention_num_layers = []\n",
    "    pointnet_cross_attention = []\n",
    "    pointnet_cross_attention_attention_types = []\n",
    "    multi_cross_attention = []\n",
    "    multi_cross_attention_attention_types = []\n",
    "\n",
    "    # result columns\n",
    "    loss = []\n",
    "    average_recall = []\n",
    "    average_1p_recall = []\n",
    "\n",
    "    for config in configs:\n",
    "        datasets.append(config['params']['dataset_name'])\n",
    "        epochs.append(config['params']['epochs'])\n",
    "        batch_size.append(config['params']['batch_size'])\n",
    "        batch_size_limit.append(config['params']['batch_size_limit'])\n",
    "        backbone.append(config['params']['model_params']['backbone'])\n",
    "        pooling.append(config['params']['model_params']['pooling'])\n",
    "\n",
    "        pointnet.append(True if 'pointnet' in config['params']['model_params']['combine_params'] else False)\n",
    "        pointnet_pnt2s.append(config['params']['model_params']['combine_params']['pointnet']['pnt2s'] if \\\n",
    "                             'pointnet' in config['params']['model_params']['combine_params'] else None)\n",
    "        self_attention.append(True if 'self_attention' in config['params']['model_params']['combine_params'] else False)\n",
    "        self_attention_num_layer = 1 if 'self_attention' in config['params']['model_params']['combine_params'] else None\n",
    "        self_attention_num_layer = config['params']['model_params']['combine_params']['self_attention']['num_layers'] if \\\n",
    "                                    'self_attention' in config['params']['model_params']['combine_params'] and \\\n",
    "                                    'num_layers' in config['params']['model_params']['combine_params']['self_attention'] else self_attention_num_layer\n",
    "        self_attention_num_layers.append(self_attention_num_layer)\n",
    "        pointnet_cross_attention.append(True if 'pointnet_cross_attention' in config['params']['model_params']['combine_params'] else False)\n",
    "        pointnet_cross_attention_attention_types.append(config['params']['model_params']['combine_params']['pointnet_cross_attention']['attention_type'] if \\\n",
    "                                                        'pointnet_cross_attention' in config['params']['model_params']['combine_params'] else None)\n",
    "        multi_cross_attention.append(True if 'multi_cross_attention' in config['params']['model_params']['combine_params'] else False)\n",
    "        multi_cross_attention_attention_types.append(config['params']['model_params']['combine_params']['multi_cross_attention']['attention_type'] if \\\n",
    "                                                        'multi_cross_attention' in config['params']['model_params']['combine_params'] else None)\n",
    "        version.append(backbone[-1]+pooling[-1])\n",
    "\n",
    "        exp_loss = []\n",
    "        for i in range(len(config['stats']['train'])):\n",
    "            exp_loss.append(float(config['stats']['train'][i]['loss']))\n",
    "        loss.append(exp_loss)\n",
    "        \n",
    "        exp_avg_recall, exp_1p_avg_recall = [], []\n",
    "        for j in range(len(config['stats']['eval'])):\n",
    "            epoch = re.match(r'(epoch[0-9]+)', next(iter(config['stats']['eval'][j]))).group(1)\n",
    "            exp_1p_avg_recall.append(float(config['stats']['eval'][j][epoch][config['params']['dataset_name'].lower()]['ave_one_percent_recall']))\n",
    "            exp_avg_recall_str = config['stats']['eval'][j][epoch][config['params']['dataset_name'].lower()]['ave_recall']\n",
    "            exp_avg_recall.append(float(re.match(r'\\[\\s*([0-9]+.[0-9]+).*', exp_avg_recall_str).group(1)))\n",
    "        average_recall.append(exp_avg_recall)\n",
    "        average_1p_recall.append(exp_1p_avg_recall)\n",
    "        assert len(average_recall) == len(average_1p_recall), 'The length of average_recall and average_1p_recall is not equal.'\n",
    "    \n",
    "    model_names = []\n",
    "    for v, p, s, pc, m in zip(version, pointnet, self_attention, pointnet_cross_attention, multi_cross_attention):\n",
    "        model_name = v\n",
    "        model_name = model_name + ' + pointnet' if p else model_name\n",
    "        model_name = model_name + ' + self_attention' if s else model_name\n",
    "        model_name = model_name + ' + pointnet_cross_attention' if pc else model_name\n",
    "        model_name = model_name + ' + multi_cross_attention' if m else model_name\n",
    "        if v == 'MinkFPNGeM' and not p and not s and not pc and not m:\n",
    "            model_name = model_name + ' Baseline'\n",
    "        model_names.append(model_name)\n",
    "\n",
    "    dirs = [d.replace('-', '_')[:-2] if int(d.split('-')[0][-3:]) < 731 else d.replace('-', '_') for d in dirs]\n",
    "    dirs = [f'model_{v}_{d}' for v,d in zip(version, dirs)]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {   'dataset_name': datasets,\n",
    "            'model_name': model_names,\n",
    "            'dir': dirs,\n",
    "            'epochs': epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'batch_size_limit': batch_size_limit,\n",
    "            'version': version,\n",
    "            'pointnet.pnt2s': pointnet_pnt2s,\n",
    "            'self_attention.num_layers': self_attention_num_layers,\n",
    "            'pointnet_cross_attention.attention_types': pointnet_cross_attention_attention_types,\n",
    "            'loss': loss,\n",
    "            'multi_cross_attention': multi_cross_attention,\n",
    "        })\n",
    "\n",
    "    metrics = {\n",
    "        'average_recall': np.array(average_recall),\n",
    "        'average_1p_recall': np.array(average_1p_recall)\n",
    "    }\n",
    "    return df, metrics\n",
    "\n",
    "\n",
    "def get_highest_by_criterion(criterion, df, metrics):\n",
    "    all_metrics = ['average_recall', 'average_1p_recall']\n",
    "    assert criterion in all_metrics, 'criterion must be one of {}'.format(all_metrics)\n",
    "    \n",
    "    criterion1 = next(iter (set(all_metrics) - set([criterion])))\n",
    "    max_vals = [np.max(l) for l in metrics[criterion]]\n",
    "    max_idx =  [np.argmax(l) for l in metrics[criterion]]\n",
    "    assert len(max_vals) == len(max_idx), 'The length of max_vals and max_idx is not equal.'\n",
    "    df['best_epoch'] = np.asarray(max_idx) + 1\n",
    "    df.loc[df['dataset_name'] != 'TUM', 'best_epoch'] =  df.loc[df['epochs'] != 'TUM', 'epochs']\n",
    "    df[criterion] = np.asarray(max_vals, dtype=\"object\")\n",
    "    df[criterion1] = np.asarray([l[i] for i, l in zip(max_idx, metrics[criterion1])],  dtype=\"object\")\n",
    "    assert criterion in df.columns and criterion1 in df.columns and 'best_epoch' in df.columns\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_results(tf_logdir):\n",
    "    \"\"\"\n",
    "    Get the table of results, return a dataframe.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tf_logdir):\n",
    "        raise ValueError('The directory {} does not exist.'.format(tf_logdir))\n",
    "\n",
    "    configs, dirs = get_finished_configs(tf_logdir)\n",
    "\n",
    "    df = get_columns(configs, dirs)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, metrics = get_results(tf_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'average_recall'\n",
    "assert criterion in ['average_1p_recall', 'average_recall']\n",
    "df_criterion = get_highest_by_criterion(criterion, df, metrics)\n",
    "df_sort_avg_recall = df_criterion.sort_values(by=['dataset_name', criterion, 'batch_size', 'batch_size_limit'], ascending=False)\n",
    "df_sort_avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = 'average_1p_recall'\n",
    "assert criterion in ['average_1p_recall', 'average_recall']\n",
    "df_criterion = get_highest_by_criterion(criterion, df, metrics)\n",
    "df_sort_avg_1p_recall = df_criterion.sort_values(by=['dataset_name', criterion, 'batch_size', 'batch_size_limit'], ascending=False)\n",
    "df_sort_avg_1p_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Avg Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tum_avg_recall_model_desc = df_sort_avg_recall.loc[df_sort_avg_recall['dataset_name'] == 'TUM'].iloc[0]\n",
    "best_tum_avg_recall_dir, best_tum_avg_recall_best_epoch = best_tum_avg_recall_model_desc['dir'], best_tum_avg_recall_model_desc['best_epoch']\n",
    "best_tum_avg_recall_model = os.path.join(weights_dir, best_tum_avg_recall_dir, f'epoch{best_tum_avg_recall_best_epoch}.pth')\n",
    "assert os.path.exists(best_tum_avg_recall_model), f'{best_tum_avg_recall_model} not exists'\n",
    "print('Best TUM average recall model:\\n\\n', best_tum_avg_recall_model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_usyd_avg_recall_model_desc = df_sort_avg_recall.loc[df_sort_avg_recall['dataset_name'] == 'USyd'].iloc[0]\n",
    "best_usyd_avg_recall_dir, best_usyd_avg_recall_best_epoch = best_usyd_avg_recall_model_desc['dir'], best_usyd_avg_recall_model_desc['best_epoch']\n",
    "best_usyd_avg_recall_model = os.path.join(weights_dir, best_usyd_avg_recall_dir, f'epoch{best_usyd_avg_recall_best_epoch}.pth')\n",
    "assert os.path.exists(best_usyd_avg_recall_model), f'{best_usyd_avg_recall_model} not exists'\n",
    "print('Best USyd average recall model:\\n\\n', best_usyd_avg_recall_model_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Avg 1p Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tum_avg_1p_recall_model_desc = df_sort_avg_1p_recall.loc[df_sort_avg_1p_recall['dataset_name'] == 'TUM'].iloc[0]\n",
    "best_tum_avg_1p_recall_dir, best_tum_avg_1p_recall_best_epoch = best_tum_avg_1p_recall_model_desc['dir'], best_tum_avg_1p_recall_model_desc['best_epoch']\n",
    "best_tum_avg_1p_recall_model = os.path.join(weights_dir, best_tum_avg_1p_recall_dir, f'epoch{best_tum_avg_1p_recall_best_epoch}.pth')\n",
    "assert os.path.exists(best_tum_avg_1p_recall_model), f'{best_tum_avg_1p_recall_model} not exists'\n",
    "print('Best TUM average 1p recall model:\\n\\n', best_tum_avg_1p_recall_model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_usyd_avg_1p_recall_model_desc = df_sort_avg_1p_recall.loc[df_sort_avg_1p_recall['dataset_name'] == 'USyd'].iloc[0]\n",
    "best_usyd_avg_1p_recall_dir, best_usyd_avg_1p_recall_best_epoch = best_usyd_avg_1p_recall_model_desc['dir'], best_usyd_avg_1p_recall_model_desc['best_epoch']\n",
    "best_usyd_avg_1p_recall_model = os.path.join(weights_dir, best_usyd_avg_1p_recall_dir, f'epoch{best_usyd_avg_1p_recall_best_epoch}.pth')\n",
    "assert os.path.exists(best_usyd_avg_1p_recall_model), f'{best_usyd_avg_1p_recall_model} not exists'\n",
    "print('Best USyd average 1p recall model:\\n\\n', best_usyd_avg_1p_recall_model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = [best_tum_avg_recall_model,\n",
    "               best_usyd_avg_recall_model,\n",
    "               best_tum_avg_1p_recall_model,\n",
    "               best_usyd_avg_1p_recall_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/xiayan/testdir/MinkLoc3D-SI/training\n",
    "# ! nohup python train.py \\\n",
    "#     --config=../config_usyd.txt \\\n",
    "#     --model_config=../config/model_config.txt > ${log_file_name}.log  2>&1 & "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/xiayan/testdir/MinkLoc3D-SI/training\n",
    "# ! nohup python train.py \\\n",
    "#     --config=../config_tum.txt \\\n",
    "#     --model_config=../config/model_config.txt > ${log_file_name}.log  2>&1 & "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Kitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_usyd_model = os.path.join(weights_dir, 'MinkLoc3D-SI-USyd.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "  \n",
    "* Change model_config.txt into the configuration of the stored model before running (using the printed information of the best models above)\n",
    "* Advice: \n",
    "    * check the config of each best model and save the txt files into a separate folder called 'best_models'\n",
    "    * change the weights paths into 'best_models/best_xx_model.txt' so that you don need to change 'model_config.txt' each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Usyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/xiayan/testdir/MinkLoc3D-SI/eval\n",
    "! python evaluate_kitti.py --config=../config/config_kitti.txt \\\n",
    "     --model_config=../config/model_config.txt \\\n",
    "     --weights=$default_usyd_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Avg Recall Usyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/xiayan/testdir/MinkLoc3D-SI/eval\n",
    "# ! python evaluate_kitti.py --config=../config/config_kitti.txt \\\n",
    "#      --model_config=../config/model_config.txt \\\n",
    "#      --weights=$best_usyd_avg_recall_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Avg 1p Recall Usyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/xiayan/testdir/MinkLoc3D-SI/eval\n",
    "# ! python evaluate_kitti.py --config=../config/config_kitti.txt \\\n",
    "#      --model_config=../config/model_config.txt \\\n",
    "#      --weights=$best_usyd_avg_1p_recall_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best TUM Avg Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/xiayan/testdir/MinkLoc3D-SI/eval\n",
    "# ! python evaluate_kitti.py --config=../config/config_kitti.txt \\\n",
    "#      --model_config=../config/model_config.txt \\\n",
    "#      --weights=$best_tum_avg_recall_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best TUM Avg 1p Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/xiayan/testdir/MinkLoc3D-SI/eval\n",
    "# ! python evaluate_kitti.py --config=../config/config_kitti.txt \\\n",
    "#      --model_config=../config/model_config.txt \\\n",
    "#      --weights=$best_tum_avg_1p_recall_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mink')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6986b7b18222a2a0e17146b18f65fe58afb9867d36210d49f16dcd185c40f9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
